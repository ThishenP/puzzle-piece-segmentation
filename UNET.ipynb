{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8816d7-1082-4f5a-8fc3-207e6120a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import img_as_float32, img_as_ubyte, img_as_uint\n",
    "from skimage.feature import canny\n",
    "from skimage.color import rgb2gray, rgb2hsv, gray2rgb, rgba2rgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "# caching with sane defaults\n",
    "from cachier import cachier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120ad08e-216c-48bf-b4b2-5b70e3dff654",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04735725-8c6e-4512-93b5-c5c3f27be91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm = partial(tqdm, position=0, leave=True)\n",
    "\n",
    "\n",
    "cachier = partial(cachier, pickle_reload=False, cache_dir=\"data/cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea52e54-6e48-4514-b4a7-bd793c6ec655",
   "metadata": {},
   "source": [
    "### Read and Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec4f778-b26a-4484-901b-f7cfcaa1c73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a748fe7ac56741458a978e9148d602a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Images:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c83d300c0f41b4bed2019a9724b020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Masks:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a028d2f154d42b58a40dcef59e35adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resizing Images:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c9be3aaae84d618e185e6305dbefb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resizing Masks:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################## Stuff for loading and rescaling the puzzle pieces nicely ################################\n",
    "SIZE = (768, 1024)\n",
    "\n",
    "DATA_PATH_PAIRS = list(\n",
    "    zip(\n",
    "        natsorted(\n",
    "            glob(\n",
    "                f\"puzzle_corners_{SIZE[1]}x{SIZE[0]}/images-{SIZE[1]}x{SIZE[0]}/*.png\"\n",
    "            )\n",
    "        ),\n",
    "        natsorted(\n",
    "            glob(\n",
    "                f\"puzzle_corners_{SIZE[1]}x{SIZE[0]}/masks-{SIZE[1]}x{SIZE[0]}/*.png\"\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "DATA_IMGS = np.array(\n",
    "    [\n",
    "        img_as_float32(imageio.imread(img_path))\n",
    "        for img_path, _ in tqdm(DATA_PATH_PAIRS, \"Loading Images\")\n",
    "    ]\n",
    ")\n",
    "DATA_MSKS = np.array(\n",
    "    [\n",
    "        img_as_float32(imageio.imread(msk_path))\n",
    "        for _, msk_path in tqdm(DATA_PATH_PAIRS, \"Loading Masks\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "SCALE = 0.25\n",
    "MATCH_IMGS = np.array([\n",
    "    cv2.resize(img, None, fx=SCALE, fy=SCALE)\n",
    "    for img in tqdm(DATA_IMGS, \"Resizing Images\")\n",
    "])\n",
    "MATCH_MSKS = np.array([\n",
    "    np.expand_dims(cv2.resize(img, None, fx=SCALE, fy=SCALE), axis=2)\n",
    "    for img in tqdm(DATA_MSKS, \"Resizing Masks\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0c71ae-87fa-4264-b4cd-ca5f088d2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e8a8d-f36f-4bc3-bd26-8398926332df",
   "metadata": {},
   "source": [
    "# Data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5be2e8cf-afcf-46cb-b13e-4b368ea354b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_count=34, val_count=7, test_count=7, random_state=42):\n",
    "    \"\"\" Split data into train, validation and test sets\"\"\"\n",
    "    # Obtain percentage split values\n",
    "    total_data_size = X.shape[0]\n",
    "    train_size = train_count / total_data_size\n",
    "    val_size = val_count / total_data_size\n",
    "    test_size = val_count / total_data_size\n",
    "   \n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
    "    val_size = val_size/(val_size+test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, train_size=val_size, random_state=random_state)\n",
    "    \n",
    "    print(f\"Training images: {X_train.shape[0]}\")\n",
    "    print(f\"Validation images: {X_val.shape[0]}\")\n",
    "    print(f\"Test images: {X_test.shape[0]}\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543b7b03-551e-459e-8f67-229595d25e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 34\n",
      "Validation images: 7\n",
      "Test images: 7\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(MATCH_IMGS, MATCH_MSKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c34992-f677-4b8b-a6d3-88935e4b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_image_aug(aug_func, X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    X_train = np.append(X_train, aug_func(X_train[:34]).numpy(), 0)\n",
    "    y_train = np.append(y_train, aug_func(y_train[:34]).numpy(), 0)\n",
    "    \n",
    "    X_val = np.append(X_val, aug_func(X_val[:7]).numpy(), 0)\n",
    "    y_val = np.append(y_val, aug_func(y_val[:7]).numpy(), 0)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835d1784-5d82-4855-b60e-2242c00cfd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_augmentations(X_train, X_val, y_train, y_val):\n",
    "    # Spatial augmentations\n",
    "    \n",
    "    ## Flipping\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = apply_image_aug(tf.image.flip_left_right, X_train, X_val, y_train, y_val)\n",
    "    X_train, X_val, y_train, y_val = apply_image_aug(tf.image.flip_up_down, X_train, X_val, y_train, y_val)    \n",
    "    \n",
    "    ## Rotation\n",
    "    \n",
    "    # Pixel augmentations\n",
    "    \n",
    "    ## Brightness\n",
    "    \n",
    "    ## Contrast\n",
    "    \n",
    "    ## Saturation\n",
    "    \n",
    "    ## Hue\n",
    "    \n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd946bbc-ce06-4686-ba9b-63749dfaed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 34\n",
      "Validation images: 7\n",
      "Test images: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training images: {X_train.shape[0]}\")\n",
    "print(f\"Validation images: {X_val.shape[0]}\")\n",
    "print(f\"Test images: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7df1d70-8037-4c8a-8146-dc1a11128a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = add_data_augmentations(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009ffe3b-bf7a-40eb-b561-dd3f77fa187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 102\n",
      "Validation images: 21\n",
      "Test images: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training images: {X_train.shape[0]}\")\n",
    "print(f\"Validation images: {X_val.shape[0]}\")\n",
    "print(f\"Test images: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e484a3-fc0a-42ba-886a-8c70c7b47af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_data(X, y):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    print(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\n",
    "        ax = axes.flatten()\n",
    "        ax[0].imshow(X[i])\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[0].title.set_text(f'{i%(X.shape[0]/3)}')\n",
    "\n",
    "        ax[1].imshow(y[i], cmap=\"gray\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[1].title.set_text(f'{i%(X.shape[0]/3)}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d27e2c3-9dab-4807-8d72-3fb2babb9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all_data(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f9890-64ce-4ed2-aaa6-6774ad98c83c",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f28ef278-0416-4674-86e5-215b8aaa83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Dice\n",
    "\n",
    "# IoU\n",
    "\n",
    "# map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24a47ba-ecda-4e1d-93e4-6736d258a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b152526-9a38-4bfc-a2ae-f5e429204ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86252143-e3be-45fe-b7bd-f16f398ab37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16_unet(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" Pre-trained VGG16 Model \"\"\"\n",
    "    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = vgg16.get_layer(\"block1_conv2\").output         ## (512 x 512)\n",
    "    s2 = vgg16.get_layer(\"block2_conv2\").output         ## (256 x 256)\n",
    "    s3 = vgg16.get_layer(\"block3_conv3\").output         ## (128 x 128)\n",
    "    s4 = vgg16.get_layer(\"block4_conv3\").output         ## (64 x 64)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = vgg16.get_layer(\"block5_conv3\").output         ## (32 x 32)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
    "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
    "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
    "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"VGG16_U-Net\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab97ba5-40dc-4992-b3d3-499da65c9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape\n",
    "model = build_vgg16_unet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66591411-aa21-4542-b078-38095cdeaed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50af487f-1d4e-4862-9969-1e07879e57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9882b8-6114-47e2-8a34-e71b32993f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 4s 59ms/step - loss: 0.0702 - accuracy: 0.9759 - mean_io_u_1: 0.3792 - val_loss: 5.3716 - val_accuracy: 0.2589 - val_mean_io_u_1: 0.4944\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 0.0331 - accuracy: 0.9864 - mean_io_u_1: 0.3763 - val_loss: 3.6780 - val_accuracy: 0.2880 - val_mean_io_u_1: 0.4561\n",
      "Epoch 3/100\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 0.0327 - accuracy: 0.9862 - mean_io_u_1: 0.3784"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20644/352568067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, y_train, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=2, \n",
    "                    verbose=1, \n",
    "                    epochs=100, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c7f7a7e-ae7d-4061-89f2-f9d673422a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"test.hdf5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e50cf01c-e84a-484a-9a5a-27ca5b2aa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, X):\n",
    "    y = model.predict(X)\n",
    "    # y = (y[:,:,:,0] > 0.5).astype(np.uint8)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2afa1e54-d86d-476a-88a2-2c957c3f9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = predict_batch(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9e1f277-b7bb-458b-beca-6ec214b96023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 192, 256, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c6fc86a-00e6-4c9c-a7ae-815fa5a1e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coe(y_true,y_pred, loss_type='jaccard', smooth=1.):\n",
    "\n",
    "    y_true_f = tf.reshape(y_true,[-1])\n",
    "    y_pred_f = tf.reshape(y_pred,[-1])\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "\n",
    "    if loss_type == 'jaccard':\n",
    "        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n",
    "\n",
    "    elif loss_type == 'sorensen':\n",
    "        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n",
    "\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb540249-c716-4f1d-a379-c26affb7d01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 192, 256, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4116958686384441"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcc160f8-bc1f-4e82-b503-080964b9ec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 256, 1)\n",
      "(192, 256, 1)\n",
      "(192, 256, 1)\n",
      "(192, 256, 1)\n",
      "(192, 256, 1)\n",
      "(192, 256, 1)\n",
      "(192, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "iou_scores = []\n",
    "for i in range(len(y_test)):\n",
    "    iou_scores.append(dice(y_test[i], y_test_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53cb9cc7-4215-42e4-b18a-30430c0692ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4111153193676747"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(iou_scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b944e56-c140-4e95-80e1-5d39b3536c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(im1, im2):\n",
    "    im1 = np.asarray(im1).astype(bool)\n",
    "    im2 = np.asarray(im2).astype(bool)\n",
    "    \n",
    "    # print(im1.shape)\n",
    "    \n",
    "    im_sum = im1.sum() + im2.sum()\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "\n",
    "    return 2. * intersection.sum() / im_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81961d-d26f-46ef-b006-76cc496b795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(im1, im2):\n",
    "    return accuracy_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a976a3a-0e0c-484d-bae9-56be4aedcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(bool)\n",
    "    y_pred = np.asarray(y_pred).astype(bool)\n",
    "    return accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c38bda39-d063-4c70-8132-4f1eb7df5070",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22995/1058234671.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpixel_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22995/39700381.py\u001b[0m in \u001b[0;36mpixel_accuracy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown is not supported"
     ]
    }
   ],
   "source": [
    "pixel_accuracy(y_test[0], y_test_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f38ad8cd-45c2-40b0-bb75-cbb288267d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(bool)\n",
    "    y_pred = np.asarray(y_pred).astype(bool)\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    union = np.logical_or(y_true, y_pred)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b65e6651-86b3-4fd7-89a3-67e77c459d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2592046828497024"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "876fbe2c-669b-44d6-a1b6-37d02050768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2592046828497024"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be643f10-211c-4b96-a3e6-b116f50364d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(bool)\n",
    "    y_pred = np.asarray(y_pred).astype(bool)\n",
    "    # intersection = np.logical_and(y_true, y_pred)\n",
    "    # union = np.logical_or(y_true, y_pred)\n",
    "    # iou_score = np.sum(intersection) / np.sum(union)\n",
    "    accuracy_score(y_true, y_pred)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ff3c3b1-6623-4d61-8cb0-c48419cfbcaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22995/816600006.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22995/2066878139.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# union = np.logical_or(y_true, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# iou_score = np.sum(intersection) / np.sum(union)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0miou_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/kavilann@gmail.com/Google Drive/Wits Com Sci/Semester 2/CV/puzzle-piece-segmentation/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown is not supported"
     ]
    }
   ],
   "source": [
    "accuracy(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee06b0f-3e53-4161-aec5-b65a0bb2a19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
