{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8816d7-1082-4f5a-8fc3-207e6120a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import img_as_float32, img_as_ubyte, img_as_uint\n",
    "from skimage.feature import canny\n",
    "from skimage.color import rgb2gray, rgb2hsv, gray2rgb, rgba2rgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "# caching with sane defaults\n",
    "from cachier import cachier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120ad08e-216c-48bf-b4b2-5b70e3dff654",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tqdm = partial(tqdm, position=0, leave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04735725-8c6e-4512-93b5-c5c3f27be91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper plot functions\n",
    "\n",
    "def plot_img(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show\n",
    "\n",
    "def plot_all_data(X, y):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    print(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\n",
    "        ax = axes.flatten()\n",
    "        ax[0].imshow(X[i])\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[0].title.set_text(f'{i%(X.shape[0]/3)}')\n",
    "\n",
    "        ax[1].imshow(y[i], cmap=\"gray\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[1].title.set_text(f'{i%(X.shape[0]/3)}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035b425-c0e9-4682-8fa6-00cb45e3b3f8",
   "metadata": {},
   "source": [
    "# UNET with VGG16 ImageNet Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d67a90-42fc-4877-9bcc-64eac91426c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet:\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "        self.model = self.create_unet_vgg16()\n",
    "        self.history = None\n",
    "        \n",
    "    def conv_block(self, x, num_filters):\n",
    "        x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        return x\n",
    "    \n",
    "    def decoder_block(self, x, skip_features, num_filters):\n",
    "        x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(x)\n",
    "        x = Concatenate()([x, skip_features])\n",
    "        x = self.conv_block(x, num_filters)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def create_unet_vgg16(self):\n",
    "        \"\"\" Input \"\"\"\n",
    "        inputs = Input(self.input_size)\n",
    "\n",
    "        \"\"\" Pre-trained VGG16 Model \"\"\"\n",
    "        vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1 = vgg16.get_layer(\"block1_conv2\").output         ## (512 x 512)\n",
    "        s2 = vgg16.get_layer(\"block2_conv2\").output         ## (256 x 256)\n",
    "        s3 = vgg16.get_layer(\"block3_conv3\").output         ## (128 x 128)\n",
    "        s4 = vgg16.get_layer(\"block4_conv3\").output         ## (64 x 64)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b1 = vgg16.get_layer(\"block5_conv3\").output         ## (32 x 32)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
    "        d2 = self.decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
    "        d3 = self.decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
    "        d4 = self.decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "        return Model(inputs, outputs, name=\"VGG16_U-Net\")\n",
    "        \n",
    "    \n",
    "    def train(self, X_train, X_val, y_train, y_val, lr=1e-3, batch_size=8, epochs=100):\n",
    "        self.model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        self.history = self.model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=1, \n",
    "                    epochs=epochs, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=False)\n",
    "    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        loss = self.history.history['loss']\n",
    "        val_loss = self.history.history['val_loss']\n",
    "        epochs = range(1, len(loss) + 1)\n",
    "        plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def plot_accuracy(self):\n",
    "        acc = self.history.history['accuracy']\n",
    "        val_acc = self.history.history['val_accuracy']\n",
    "        epochs = range(1, len(acc) + 1)\n",
    "        plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "        plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def predict_batch(self, x):\n",
    "        y = self.model.predict(x)\n",
    "        y = (y[:,:,:,0] > 0.5).astype(np.uint8)\n",
    "        return y\n",
    "    \n",
    "    def evaluate_model(self, X, y_true):\n",
    "        y_pred = self.predict_batch(X)\n",
    "        y_pred = np.squeeze(y_pred)\n",
    "        y_true = np.squeeze(y_true)\n",
    "        print(f\"Accuracy: {pixel_accuracy(y_true, y_pred)}\")\n",
    "        print(f\"Dice: {dice(y_true, y_pred)}\")\n",
    "        print(f\"IoU: {iou(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ef14c-1526-4f79-9b1f-014449990dd3",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96e8493-857c-4ee3-a4d9-b152a6f00bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(bool)\n",
    "    y_pred = np.asarray(y_pred).astype(bool)\n",
    "    \n",
    "    im_sum = y_true.sum() + y_pred.sum()\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "\n",
    "    return 2. * intersection.sum() / im_sum\n",
    "\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(np.uint8).flatten()\n",
    "    y_pred = np.asarray(y_pred).astype(np.uint8).flatten()\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(bool)\n",
    "    y_pred = np.asarray(y_pred).astype(bool)\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    union = np.logical_or(y_true, y_pred)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f4eccf-3c61-4f0d-a680-1228f3e8f36d",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ade04ab-501f-41bc-9071-68212e4d622f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1c7a6178be412997695b1ee1e14395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Images:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a7485cf60f415ca7c5db211d7a92e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Masks:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65a85186fa34ba1851519f1b4bad26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resizing Images:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0c26c02fee4096abd4fb161089e2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resizing Masks:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SIZE = (768, 1024)\n",
    "\n",
    "DATA_PATH_PAIRS = list(\n",
    "    zip(\n",
    "        natsorted(\n",
    "            glob(\n",
    "                f\"puzzle_corners_{SIZE[1]}x{SIZE[0]}/images-{SIZE[1]}x{SIZE[0]}/*.png\"\n",
    "            )\n",
    "        ),\n",
    "        natsorted(\n",
    "            glob(\n",
    "                f\"puzzle_corners_{SIZE[1]}x{SIZE[0]}/masks-{SIZE[1]}x{SIZE[0]}/*.png\"\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "DATA_IMGS = np.array(\n",
    "    [\n",
    "        img_as_float32(imageio.imread(img_path))\n",
    "        for img_path, _ in tqdm(DATA_PATH_PAIRS, \"Loading Images\")\n",
    "    ]\n",
    ")\n",
    "DATA_MSKS = np.array(\n",
    "    [\n",
    "        img_as_float32(imageio.imread(msk_path))\n",
    "        for _, msk_path in tqdm(DATA_PATH_PAIRS, \"Loading Masks\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "SCALE = 0.25\n",
    "MATCH_IMGS = np.array([\n",
    "    cv2.resize(img, None, fx=SCALE, fy=SCALE)\n",
    "    for img in tqdm(DATA_IMGS, \"Resizing Images\")\n",
    "])\n",
    "MATCH_MSKS = np.array([\n",
    "    np.expand_dims(cv2.resize(img, None, fx=SCALE, fy=SCALE), axis=2)\n",
    "    for img in tqdm(DATA_MSKS, \"Resizing Masks\")\n",
    "])\n",
    "    \n",
    "    # Should I be normalizing the data? \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4c854-ff3e-4cae-9a36-55a23f54fff9",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5d837f-00cd-498b-9d0f-b4e097c54f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_count=34, val_count=7, test_count=7, random_state=42):\n",
    "    \"\"\" Split data into train, validation and test sets\"\"\"\n",
    "    # Obtain percentage split values\n",
    "    total_data_size = X.shape[0]\n",
    "    train_size = train_count / total_data_size\n",
    "    val_size = val_count / total_data_size\n",
    "    test_size = val_count / total_data_size\n",
    "   \n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
    "    val_size = val_size/(val_size+test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, train_size=val_size, random_state=random_state)\n",
    "    \n",
    "    print(f\"Training images: {X_train.shape[0]}\")\n",
    "    print(f\"Validation images: {X_val.shape[0]}\")\n",
    "    print(f\"Test images: {X_test.shape[0]}\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12cffb24-6381-47ef-8247-124586255231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 34\n",
      "Validation images: 7\n",
      "Test images: 7\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(MATCH_IMGS, MATCH_MSKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e8a8d-f36f-4bc3-bd26-8398926332df",
   "metadata": {},
   "source": [
    "# Data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be2e8cf-afcf-46cb-b13e-4b368ea354b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_image_aug(aug_func, X_train, X_val, y_train, y_val, aug_target=True, args={}):\n",
    "    \n",
    "    X_train = np.append(X_train, aug_func(X_train[:34], **args).numpy(), 0)\n",
    "    \n",
    "    \n",
    "    X_val = np.append(X_val, aug_func(X_val[:7], **args).numpy(), 0)\n",
    "    \n",
    "    \n",
    "    if aug_target:\n",
    "        y_train = np.append(y_train, aug_func(y_train[:34], **args).numpy(), 0)\n",
    "        y_val = np.append(y_val, aug_func(y_val[:7], **args).numpy(), 0)\n",
    "    else:\n",
    "        y_train = np.append(y_train, y_train[:34], 0)\n",
    "        y_val = np.append(y_val, y_val[:7], 0)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def add_data_augmentations(X_train, X_val, y_train, y_val):\n",
    "    # Spatial augmentations\n",
    "    \n",
    "    ## Flipping\n",
    "    X_train, X_val, y_train, y_val = apply_image_aug(tf.image.flip_left_right, X_train, X_val, y_train, y_val)\n",
    "    X_train, X_val, y_train, y_val = apply_image_aug(tf.image.flip_up_down, X_train, X_val, y_train, y_val)    \n",
    "    \n",
    "    # ## Rotation\n",
    "    # X_train, X_val, y_train, y_val = apply_image_aug(tf.image.rot90, X_train, X_val, y_train, y_val)\n",
    "    \n",
    "    # Pixel augmentations\n",
    "    \n",
    "    ## Brightness\n",
    "    X_train, X_val, y_train, y_val = apply_image_aug(tf.image.random_brightness, X_train, X_val, y_train, y_val, aug_target=False, args={\"max_delta\": 0.25})    \n",
    "    \n",
    "    ## Contrast\n",
    "    \n",
    "    ## Saturation\n",
    "    \n",
    "    ## Hue\n",
    "    \n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0333a51-f0f5-40a6-bdad-42f9e0e6a6c5",
   "metadata": {},
   "source": [
    "# Training model with no data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221c3780-bb96-4b94-adbe-135ae20a0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(input_size=X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "914f30f2-c701-4cb1-b292-a3f1a941bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = Unet(input_size=X_train[0].shape).model\n",
    "    # model.compile(optimizer=Adam(learning_rate=trial.suggest_categorical('lr', [1e-2, 1e-3]), loss='binary_crossentropy', metrics=['accuracy']))\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, \n",
    "            batch_size=trial.suggest_categorical('batch_size', [8, 16]), \n",
    "            verbose=1, \n",
    "            epochs=trial.suggest_categorical('epochs', [8, 16]), \n",
    "            validation_data=(X_test, y_test), \n",
    "            shuffle=False)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred[:,:,:,0] > 0.5).astype(np.uint8)\n",
    "    \n",
    "    return pixel_accuracy(y_val, y_pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47ad039a-4fbc-4023-93ff-f2d00cbd74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6070b7b2-2ff3-4920-b5c2-8dcf593b1924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "5/5 [==============================] - 2s 158ms/step - loss: 0.4386 - accuracy: 0.8027 - val_loss: 58.3468 - val_accuracy: 0.2552\n",
      "Epoch 2/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1269 - accuracy: 0.9706 - val_loss: 1102.4135 - val_accuracy: 0.2552\n",
      "Epoch 3/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0914 - accuracy: 0.9789 - val_loss: 772.3591 - val_accuracy: 0.2552\n",
      "Epoch 4/8\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0801 - accuracy: 0.9802 - val_loss: 176.9095 - val_accuracy: 0.2552\n",
      "Epoch 5/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0646 - accuracy: 0.9844 - val_loss: 566.5128 - val_accuracy: 0.2552\n",
      "Epoch 6/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0556 - accuracy: 0.9871 - val_loss: 351.6550 - val_accuracy: 0.2552\n",
      "Epoch 7/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0471 - accuracy: 0.9889 - val_loss: 217.5869 - val_accuracy: 0.2553\n",
      "Epoch 8/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0407 - accuracy: 0.9908 - val_loss: 328.8432 - val_accuracy: 0.2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-11 17:14:05,116]\u001b[0m Finished trial#0 resulted in value: 0.24461437406994047. Current best value is 0.24461437406994047 with parameters: {'batch_size': 8, 'epochs': 8}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "5/5 [==============================] - 2s 157ms/step - loss: 0.3805 - accuracy: 0.8844 - val_loss: 45.9912 - val_accuracy: 0.2552\n",
      "Epoch 2/16\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1220 - accuracy: 0.9696 - val_loss: 55.1615 - val_accuracy: 0.2552\n",
      "Epoch 3/16\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0927 - accuracy: 0.9789 - val_loss: 411.6328 - val_accuracy: 0.2552\n",
      "Epoch 4/16\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0763 - accuracy: 0.9829 - val_loss: 83.0115 - val_accuracy: 0.2553\n",
      "Epoch 5/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0656 - accuracy: 0.9846 - val_loss: 27.4462 - val_accuracy: 0.2572\n",
      "Epoch 6/16\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0536 - accuracy: 0.9878 - val_loss: 16.4431 - val_accuracy: 0.2680\n",
      "Epoch 7/16\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0454 - accuracy: 0.9905 - val_loss: 8.1509 - val_accuracy: 0.2810\n",
      "Epoch 8/16\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0392 - accuracy: 0.9917 - val_loss: 4.9255 - val_accuracy: 0.2937\n",
      "Epoch 9/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0350 - accuracy: 0.9923 - val_loss: 8.1552 - val_accuracy: 0.2764\n",
      "Epoch 10/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0311 - accuracy: 0.9929 - val_loss: 3.9654 - val_accuracy: 0.2922\n",
      "Epoch 11/16\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0288 - accuracy: 0.9930 - val_loss: 7.1761 - val_accuracy: 0.2813\n",
      "Epoch 12/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0268 - accuracy: 0.9931 - val_loss: 8.1736 - val_accuracy: 0.2992\n",
      "Epoch 13/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 4.1259 - val_accuracy: 0.3235\n",
      "Epoch 14/16\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 3.1636 - val_accuracy: 0.3159\n",
      "Epoch 15/16\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 4.5300 - val_accuracy: 0.3003\n",
      "Epoch 16/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 2.5397 - val_accuracy: 0.3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-11 17:14:16,013]\u001b[0m Finished trial#1 resulted in value: 0.30875941685267855. Current best value is 0.30875941685267855 with parameters: {'batch_size': 8, 'epochs': 16}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3/3 [==============================] - 2s 233ms/step - loss: 0.6021 - accuracy: 0.7021 - val_loss: 23.5327 - val_accuracy: 0.2552\n",
      "Epoch 2/8\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1837 - accuracy: 0.9589 - val_loss: 135.9676 - val_accuracy: 0.2553\n",
      "Epoch 3/8\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1138 - accuracy: 0.9732 - val_loss: 553.3302 - val_accuracy: 0.2552\n",
      "Epoch 4/8\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0921 - accuracy: 0.9791 - val_loss: 463.5516 - val_accuracy: 0.2552\n",
      "Epoch 5/8\n",
      "3/3 [==============================] - 1s 144ms/step - loss: 0.0779 - accuracy: 0.9811 - val_loss: 151.0225 - val_accuracy: 0.2553\n",
      "Epoch 6/8\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0676 - accuracy: 0.9835 - val_loss: 91.7852 - val_accuracy: 0.2555\n",
      "Epoch 7/8\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0565 - accuracy: 0.9874 - val_loss: 117.6369 - val_accuracy: 0.2586\n",
      "Epoch 8/8\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0495 - accuracy: 0.9891 - val_loss: 105.5407 - val_accuracy: 0.2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-11 17:14:21,688]\u001b[0m Finished trial#2 resulted in value: 0.24659075055803573. Current best value is 0.30875941685267855 with parameters: {'batch_size': 8, 'epochs': 16}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "5/5 [==============================] - 2s 158ms/step - loss: 0.3517 - accuracy: 0.8766 - val_loss: 34.7470 - val_accuracy: 0.2552\n",
      "Epoch 2/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.1350 - accuracy: 0.9649 - val_loss: 106.7651 - val_accuracy: 0.2552\n",
      "Epoch 3/8\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0908 - accuracy: 0.9809 - val_loss: 558.4820 - val_accuracy: 0.2552\n",
      "Epoch 4/8\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0748 - accuracy: 0.9834 - val_loss: 574.9440 - val_accuracy: 0.2552\n",
      "Epoch 5/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0604 - accuracy: 0.9874 - val_loss: 287.4830 - val_accuracy: 0.2552\n",
      "Epoch 6/8\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0507 - accuracy: 0.9886 - val_loss: 621.4589 - val_accuracy: 0.2552\n",
      "Epoch 7/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0429 - accuracy: 0.9911 - val_loss: 302.2166 - val_accuracy: 0.2554\n",
      "Epoch 8/8\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0369 - accuracy: 0.9919 - val_loss: 114.8265 - val_accuracy: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-11 17:14:27,966]\u001b[0m Finished trial#3 resulted in value: 0.24707903180803573. Current best value is 0.30875941685267855 with parameters: {'batch_size': 8, 'epochs': 16}.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16d388a9-538b-4763-bf72-9dbb0b044b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 4\n",
      "Best trial:\n",
      "  Value: 0.30875941685267855\n",
      "  Params: \n",
      "    batch_size: 8\n",
      "    epochs: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93343e74-b25b-42ff-abe2-435bef371247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2768467494419643\n"
     ]
    }
   ],
   "source": [
    "print(study.best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "910dd0e6-9538-4812-83b2-48522c43e665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-11-11 17:04:33.461733] [OptKeras] Ready for optimization. (message printed as verbose is set to 1+)\n",
      "Epoch 1/16\n",
      "3/3 [==============================] - 9s 1s/step - loss: 0.5843 - accuracy: 0.7060 - val_loss: 8.2917 - val_accuracy: 0.2565\n",
      "Epoch 2/16\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1972 - accuracy: 0.9577 - val_loss: 147.7888 - val_accuracy: 0.2552\n",
      "Epoch 3/16\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1335 - accuracy: 0.9697 - val_loss: 311.5243 - val_accuracy: 0.2552\n",
      "Epoch 4/16\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.0994 - accuracy: 0.9793 - val_loss: 851.0480 - val_accuracy: 0.2552\n",
      "Epoch 5/16\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.0905 - accuracy: 0.9803 - val_loss: 250.8889 - val_accuracy: 0.2552\n",
      "Epoch 6/16\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.0758 - accuracy: 0.9853 - val_loss: 132.1783 - val_accuracy: 0.2552\n",
      "Epoch 7/16\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.0661 - accuracy: 0.9865 - val_loss: 170.3830 - val_accuracy: 0.2552\n",
      "Epoch 8/16\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.0585 - accuracy: 0.9887 - val_loss: 178.5751 - val_accuracy: 0.2552\n",
      "Epoch 9/16\n",
      "3/3 [==============================] - 1s 151ms/step - loss: 0.0528 - accuracy: 0.9894 - val_loss: 69.6595 - val_accuracy: 0.2552\n",
      "Epoch 10/16\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.0479 - accuracy: 0.9904 - val_loss: 91.0082 - val_accuracy: 0.2553\n",
      "Epoch 11/16\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0438 - accuracy: 0.9913 - val_loss: 82.3896 - val_accuracy: 0.2638\n",
      "Epoch 12/16\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0409 - accuracy: 0.9918 - val_loss: 169.1515 - val_accuracy: 0.2557\n",
      "Epoch 13/16\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0386 - accuracy: 0.9919 - val_loss: 109.9808 - val_accuracy: 0.2576\n",
      "Epoch 14/16\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0357 - accuracy: 0.9925 - val_loss: 152.7542 - val_accuracy: 0.2554\n",
      "Epoch 15/16\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0342 - accuracy: 0.9924 - val_loss: 56.6831 - val_accuracy: 0.2584\n",
      "Epoch 16/16\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.0326 - accuracy: 0.9926 - val_loss: 25.6858 - val_accuracy: 0.2663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-11 17:04:50,962]\u001b[0m Finished trial#0 resulted in value: inf. Current best value is inf with parameters: {'batch_size': 16, 'epochs': 16}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "5/5 [==============================] - 4s 171ms/step - loss: 0.3047 - accuracy: 0.9084 - val_loss: 12.6150 - val_accuracy: 0.2552\n",
      "Epoch 2/16\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.1080 - accuracy: 0.9712 - val_loss: 69.1161 - val_accuracy: 0.2552\n",
      "Epoch 3/16\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0853 - accuracy: 0.9789 - val_loss: 238.0980 - val_accuracy: 0.2552\n",
      "Epoch 4/16\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0679 - accuracy: 0.9835 - val_loss: 234.3112 - val_accuracy: 0.2552\n",
      "Epoch 5/16\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0547 - accuracy: 0.9869 - val_loss: 237.6750 - val_accuracy: 0.2553\n",
      "Epoch 6/16\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0442 - accuracy: 0.9893 - val_loss: 124.5253 - val_accuracy: 0.2553\n",
      "Epoch 7/16\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 27.1986 - val_accuracy: 0.2563\n",
      "Epoch 8/16\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 110.0932 - val_accuracy: 0.2564\n",
      "Epoch 9/16\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0280 - accuracy: 0.9924 - val_loss: 69.3832 - val_accuracy: 0.2678\n",
      "Epoch 10/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 38.0129 - val_accuracy: 0.2741\n",
      "Epoch 11/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 23.4288 - val_accuracy: 0.2698\n",
      "Epoch 12/16\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 13.0860 - val_accuracy: 0.3231\n",
      "Epoch 13/16\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 4.8018 - val_accuracy: 0.4150\n",
      "Epoch 14/16\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 10.2971 - val_accuracy: 0.3318\n",
      "Epoch 15/16\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 3.5822 - val_accuracy: 0.4139\n",
      "Epoch 16/16\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.6342 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-11 17:05:04,391]\u001b[0m Finished trial#1 resulted in value: inf. Current best value is inf with parameters: {'batch_size': 16, 'epochs': 16}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-11-11 17:05:04.395357] Trial#: 1, value: inf| Best trial#: 0, value: inf, params: {'batch_size': 16, 'epochs': 16}\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "from optkeras.optkeras import OptKeras\n",
    "import optkeras\n",
    "\n",
    "study_name = \"Optuna Test\"\n",
    "\n",
    "\"\"\" Step 1. Instantiate OptKeras class\n",
    "You can specify arguments for Optuna's create_study method and other arguments \n",
    "for OptKeras such as enable_pruning. \n",
    "\"\"\"\n",
    "\n",
    "ok = OptKeras(study_name=study_name,\n",
    "              monitor='val_acc',\n",
    "              direction='maximize')\n",
    "\n",
    "\n",
    "\"\"\" Step 2. Define objective function for Optuna \"\"\"\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    \"\"\" Step 2.1. Define parameters to try using methods of optuna.trial such as \n",
    "    suggest_categorical. In this simple demo, try 2*2*2*2 = 16 parameter sets: \n",
    "    2 values specified in list for each of 4 parameters \n",
    "    (filters, kernel_size, strides, and activation for convolution).\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Unet(input_size=X_train[0].shape).model\n",
    "    # model.compile(optimizer=Adam(learning_rate=trial.suggest_categorical('lr', [1e-2, 1e-3]), loss='binary_crossentropy', metrics=['accuracy']))\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, \n",
    "            batch_size=trial.suggest_categorical('batch_size', [8, 16]), \n",
    "            verbose=1, \n",
    "            epochs=trial.suggest_categorical('epochs', [8, 16]), \n",
    "            validation_data=(X_test, y_test), \n",
    "            shuffle=False)\n",
    "    \n",
    "    \"\"\" Step 2.3. Return trial_best_value (or latest_value) \"\"\"\n",
    "    # print(ok)\n",
    "    return ok.trial_best_value\n",
    "\n",
    "\"\"\" Step 3. Run optimize. \n",
    "Set n_trials and/or timeout (in sec) for optimization by Optuna\n",
    "\"\"\"\n",
    "ok.optimize(objective, n_trials = 2) # Run for 3 minutes for demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2b9848-b164-4f37-a313-519c252ef10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optkeras==0.0.7 in ./venv/lib/python3.8/site-packages (0.0.7)\n",
      "Requirement already satisfied: optuna>=0.9.0 in ./venv/lib/python3.8/site-packages (from optkeras==0.0.7) (0.14.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from optkeras==0.0.7) (1.20.0)\n",
      "Requirement already satisfied: keras in ./venv/lib/python3.8/site-packages (from optkeras==0.0.7) (2.7.0)\n",
      "Requirement already satisfied: typing in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (3.7.4.3)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (1.7.2)\n",
      "Requirement already satisfied: alembic in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (1.7.4)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (1.3.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (1.4.26)\n",
      "Requirement already satisfied: colorlog in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (6.6.0)\n",
      "Requirement already satisfied: cliff in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (3.9.0)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.8/site-packages (from optuna>=0.9.0->optkeras==0.0.7) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna>=0.9.0->optkeras==0.0.7) (1.1.2)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.8/site-packages (from alembic->optuna>=0.9.0->optkeras==0.0.7) (5.4.0)\n",
      "Requirement already satisfied: importlib-metadata in ./venv/lib/python3.8/site-packages (from alembic->optuna>=0.9.0->optkeras==0.0.7) (4.8.2)\n",
      "Requirement already satisfied: Mako in ./venv/lib/python3.8/site-packages (from alembic->optuna>=0.9.0->optkeras==0.0.7) (1.1.5)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in ./venv/lib/python3.8/site-packages (from cliff->optuna>=0.9.0->optkeras==0.0.7) (2.4.7)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in ./venv/lib/python3.8/site-packages (from cliff->optuna>=0.9.0->optkeras==0.0.7) (5.7.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in ./venv/lib/python3.8/site-packages (from cliff->optuna>=0.9.0->optkeras==0.0.7) (6.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in ./venv/lib/python3.8/site-packages (from cliff->optuna>=0.9.0->optkeras==0.0.7) (3.5.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in ./venv/lib/python3.8/site-packages (from cliff->optuna>=0.9.0->optkeras==0.0.7) (2.4.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in ./venv/lib/python3.8/site-packages (from cliff->optuna>=0.9.0->optkeras==0.0.7) (2.2.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in ./venv/lib/python3.8/site-packages (from cliff->optuna>=0.9.0->optkeras==0.0.7) (0.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/lib/python3.8/site-packages (from pandas->optuna>=0.9.0->optkeras==0.0.7) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/lib/python3.8/site-packages (from pandas->optuna>=0.9.0->optkeras==0.0.7) (2.8.2)\n",
      "Requirement already satisfied: pyperclip>=1.6 in ./venv/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna>=0.9.0->optkeras==0.0.7) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in ./venv/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna>=0.9.0->optkeras==0.0.7) (0.2.5)\n",
      "Requirement already satisfied: colorama>=0.3.7 in ./venv/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna>=0.9.0->optkeras==0.0.7) (0.4.4)\n",
      "Requirement already satisfied: attrs>=16.3.0 in ./venv/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna>=0.9.0->optkeras==0.0.7) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.8/site-packages (from importlib-metadata->alembic->optuna>=0.9.0->optkeras==0.0.7) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./venv/lib/python3.8/site-packages (from Mako->alembic->optuna>=0.9.0->optkeras==0.0.7) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optkeras==0.0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "764af0ee-d633-4033-aa87-411ad1e98b5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfsdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55439/338603609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masdfsdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdfsdf' is not defined"
     ]
    }
   ],
   "source": [
    "print(asdfsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068d396-8023-4bc6-bd61-a748d10dfafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e4b8b-f1ab-4b46-9b6d-928fe51b2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.train(X_train, X_val, y_train, y_val, lr=1e-3, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfafd6-a714-4dc9-8ddc-58b5fefa491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace797d-95fd-4de0-bbab-59cc6026fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e6c8da-4eb6-44cc-815b-0726a271dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bef3f-86a9-48e9-b8e9-abae76340671",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.evaluate_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22a90d-a50d-4c7b-b3bf-07ed4e95467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.evaluate_model(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41cc47a-952f-48c2-922d-ad45efd4a5f6",
   "metadata": {},
   "source": [
    "# Training model with data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94b346-6e8e-4d98-842d-b69a58b0715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = add_data_augmentations(X_train, X_val, y_train, y_val)\n",
    "print(f\"Training images: {X_train.shape[0]}\")\n",
    "print(f\"Validation images: {X_val.shape[0]}\")\n",
    "print(f\"Test images: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa24e2a-7e57-493f-9178-277febeadcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(input_size=X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b917778-ddec-45d6-ad2b-39d03df3527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.train(X_train, X_val, y_train, y_val, lr=1e-3, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5720d9d-82b5-47c1-bcc2-798e33020fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad569ba-0367-4b10-92a0-876f5cdb68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af4436-12d6-4972-b421-81b9bf91d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb90770-137e-4d97-b4d3-ba6f312e1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.evaluate_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471de3d1-7815-4453-935d-ad63ceb545e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.evaluate_model(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077df8e2-7e9a-4e3a-b276-f6a707726f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU\n",
    "n_classes = 2\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(unet.predict_batch(X_test), y_test)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e089a83-9d1b-40a2-901c-b2866ee4218d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9292de1-e998-4874-8a95-a0f158cb18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ccbf5-503b-44fc-affe-437890ef104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Accuracy\n",
    "acc_keras = Accuracy()  \n",
    "acc_keras.update_state(unet.predict_batch(X_test), y_test)\n",
    "print(\"Acc =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270be031-b1a1-4742-a07b-2565558ea8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45183506-5a24-4427-8c30-e762cce9dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = KerasClassifier(unet.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df3c6d4-d42a-424d-8179-2747f9df45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf2dab-fbc1-4b2d-80aa-d8889b2d2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(input_size=X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c74fe-432f-457a-999a-06d9cf61b522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2978d-9552-4700-a76d-0dcbe24f3bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1b65f-6525-4227-b6c4-46b355b42844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702774e-7778-47f1-827b-247bed0d12d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
